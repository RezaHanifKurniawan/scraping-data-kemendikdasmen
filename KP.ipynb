{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd2feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.30.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Collecting websocket-client<2.0,>=1.8.0 (from selenium)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting attrs>=23.2.0 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
      "Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.6 MB 13.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 9.8 MB/s  0:00:01\n",
      "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl (182 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, sniffio, pysocks, pycparser, h11, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "\n",
      "   --- ------------------------------------  1/13 [websocket-client]\n",
      "   --------- ------------------------------  3/13 [pysocks]\n",
      "   ------------ ---------------------------  4/13 [pycparser]\n",
      "   ------------------ ---------------------  6/13 [attrs]\n",
      "   ------------------------ ---------------  8/13 [outcome]\n",
      "   --------------------------- ------------  9/13 [cffi]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ---------------------------------------- 13/13 [selenium]\n",
      "\n",
      "Successfully installed attrs-25.4.0 cffi-2.0.0 h11-0.16.0 outcome-1.3.0.post0 pycparser-2.23 pysocks-1.7.1 selenium-4.36.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.31.0 trio-websocket-0.12.2 websocket-client-1.9.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf0ff2",
   "metadata": {},
   "source": [
    "##  Ambil List Kode dan Nama Kecamatan\n",
    "\n",
    "Tahapan ini berfungsi untuk **mengambil dan memetakan daftar kode serta nama kecamatan** di Kabupaten Semarang, yang kemudian digunakan dalam dua fungsi utama sistem:\n",
    "\n",
    "1. **Sebagai dasar penyusunan URL dinamis untuk proses scraping**, dan  \n",
    "2. **Sebagai sumber data untuk dropdown pemilihan kecamatan pada tahap antarmuka (deployment)**\n",
    "\n",
    "---\n",
    "Setiap halaman daftar sekolah pada situs resmi **Kemendikdasmen** mengikuti pola URL yang tetap:\n",
    "https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3\n",
    "\n",
    "Bagian `{kode_kecamatan}` menunjukkan **identitas numerik unik** untuk setiap kecamatan.  \n",
    "Contoh:\n",
    "- Kecamatan *Ambarawa* memiliki kode `032210`,  \n",
    "\n",
    "Untuk mendapatkan kode ini secara sistematis, sistem membaca file JSON lokal (misalnya `kecamatan_kab_semarang.json`) yang berisi pasangan:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Kab. Semarang\": {\n",
    "    \"kode\": \"032200\",\n",
    "    \"kecamatan\": {\n",
    "      \"Ambarawa\": \"032210\",\n",
    "      \"Tengaran\": \"032202\",\n",
    "      \"Susukan\": \"032203\",\n",
    "      ....\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengambil daftar kabupaten/kota di Provinsi Jawa Tengah...\n",
      "\n",
      "Daftar Kabupaten/Kota di Jawa Tengah:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'030100 - Kab. Cilacap'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030200 - Kab. Banyumas'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030300 - Kab. Purbalingga'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030400 - Kab. Banjarnegara'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030500 - Kab. Kebumen'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030600 - Kab. Purworejo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030700 - Kab. Wonosobo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030800 - Kab. Magelang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'030900 - Kab. Boyolali'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031000 - Kab. Klaten'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031100 - Kab. Sukoharjo'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031200 - Kab. Wonogiri'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031300 - Kab. Karanganyar'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031400 - Kab. Sragen'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031500 - Kab. Grobogan'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031600 - Kab. Blora'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031700 - Kab. Rembang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031800 - Kab. Pati'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'031900 - Kab. Kudus'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032000 - Kab. Jepara'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032100 - Kab. Demak'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032200 - Kab. Semarang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032300 - Kab. Temanggung'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032400 - Kab. Kendal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032500 - Kab. Batang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032600 - Kab. Pekalongan'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032700 - Kab. Pemalang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032800 - Kab. Tegal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'032900 - Kab. Brebes'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036000 - Kota Magelang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036100 - Kota Surakarta'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036200 - Kota Salatiga'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036300 - Kota Semarang'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036400 - Kota Pekalongan'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'036500 - Kota Tegal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Mengambil daftar kecamatan di Kab. Semarang...\n",
      "Berhasil ambil 19 kecamatan dari Kab. Semarang\n",
      "Data disimpan ke: data\\kecamatan_kab_semarang.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "def setup_driver(headless=True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    # options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_table_rows(driver, url):\n",
    "    \"\"\"Helper untuk ambil semua baris dari tabel referensi\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\"))\n",
    "    )\n",
    "    try:\n",
    "        select = Select(driver.find_element(By.NAME, \"table1_length\"))\n",
    "        select.select_by_value(\"100\")\n",
    "    except:\n",
    "        pass\n",
    "    return driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "\n",
    "\n",
    "def get_kecamatan_jateng_by_kode():\n",
    "    \"\"\"\n",
    "    Ambil daftar kabupaten/kota di Jawa Tengah (030000),\n",
    "    input kode kabupaten/kota (misal 032200),\n",
    "    hasil disimpan ke data/kecamatan_<nama_kab>.json\n",
    "    dalam format JSON hierarkis.\n",
    "    \"\"\"\n",
    "    base_url = \"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/\"\n",
    "    driver = setup_driver(headless=True)\n",
    "    kecamatan_list = []\n",
    "\n",
    "    try:\n",
    "        # 1Ô∏è‚É£ Ambil daftar kabupaten/kota di Provinsi Jawa Tengah\n",
    "        print(\"Mengambil daftar kabupaten/kota di Provinsi Jawa Tengah...\")\n",
    "        kab_url = base_url + \"030000/1\"\n",
    "        rows_kab = get_table_rows(driver, kab_url)\n",
    "\n",
    "        kabupaten_list = []\n",
    "        for r in rows_kab:\n",
    "            try:\n",
    "                nama = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                kode = href.split(\"/\")[-2]\n",
    "                kabupaten_list.append({\"nama\": nama, \"kode\": kode})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(\"\\nDaftar Kabupaten/Kota di Jawa Tengah:\")\n",
    "        print(\"=\" * 60)\n",
    "        for k in kabupaten_list:\n",
    "            display(f\"{k['kode']} - {k['nama']}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        kode_input = input(\"\\nMasukkan KODE kabupaten/kota yang ingin discrap (contoh: 032200): \").strip()\n",
    "\n",
    "        kab = next((k for k in kabupaten_list if k[\"kode\"] == kode_input), None)\n",
    "        if not kab:\n",
    "            print(\"Kode tidak ditemukan dalam daftar.\")\n",
    "            driver.quit()\n",
    "            return []\n",
    "\n",
    "        print(f\"\\nMengambil daftar kecamatan di {kab['nama']}...\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Ambil daftar kecamatan dari kabupaten/kota terpilih\n",
    "        kec_url = base_url + f\"{kab['kode']}/2\"\n",
    "        rows_kec = get_table_rows(driver, kec_url)\n",
    "\n",
    "        for r in rows_kec:\n",
    "            try:\n",
    "                nama = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                kode = href.split(\"/\")[-2]\n",
    "                kecamatan_list.append({\"nama\": nama, \"kode\": kode, \"url\": href})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(f\"Berhasil ambil {len(kecamatan_list)} kecamatan dari {kab['nama']}\")\n",
    "\n",
    "        # 3Ô∏è‚É£ Simpan hasil ke list_kecamatan/\n",
    "        os.makedirs(\"list_kecamatan\", exist_ok=True)\n",
    "        safe_name = kab[\"nama\"].replace(\" \", \"_\").replace(\".\", \"\").lower()\n",
    "        save_path = os.path.join(\"list_kecamatan\", f\"kecamatan_{safe_name}.json\")\n",
    "\n",
    "        # === Format sesuai contoh Prof ===\n",
    "        json_data = {\n",
    "            kab[\"nama\"]: {\n",
    "                \"kode\": kab[\"kode\"],\n",
    "                \"kecamatan\": {k[\"nama\"]: k[\"kode\"] for k in kecamatan_list}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"Data disimpan ke: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi kesalahan: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return kecamatan_list\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# MAIN\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    kecamatan_data = get_kecamatan_jateng_by_kode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb0bf4",
   "metadata": {},
   "source": [
    "# GRADIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8769021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting undetected-chromedriver\n",
      "  Downloading undetected-chromedriver-3.5.5.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: gradio in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (5.49.1)\n",
      "Requirement already satisfied: selenium>=4.9.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from undetected-chromedriver) (4.36.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from undetected-chromedriver) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.119.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.6.3)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.35.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.2.6)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.11.10)\n",
      "Requirement already satisfied: pydub in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.14.1)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.48.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.19.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio-client==1.13.3->gradio) (2025.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: trio<1.0,>=0.30.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (0.12.2)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium>=4.9.0->undetected-chromedriver) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium>=4.9.0->undetected-chromedriver) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium>=4.9.0->undetected-chromedriver) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium>=4.9.0->undetected-chromedriver) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium>=4.9.0->undetected-chromedriver) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium>=4.9.0->undetected-chromedriver) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium>=4.9.0->undetected-chromedriver) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.30.0->selenium>=4.9.0->undetected-chromedriver) (2.23)\n",
      "Building wheels for collected packages: undetected-chromedriver\n",
      "  Building wheel for undetected-chromedriver (setup.py): started\n",
      "  Building wheel for undetected-chromedriver (setup.py): finished with status 'done'\n",
      "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.5.5-py3-none-any.whl size=47215 sha256=07c194f4370a3b0397cf810efb78f1afe7a663f4f05e3e0c8766294aff2a59cf\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\cf\\a1\\db\\e1275b6f7259aacd6b045f8bfcb1fcbc93827a3916ba55d5b7\n",
      "Successfully built undetected-chromedriver\n",
      "Installing collected packages: undetected-chromedriver\n",
      "Successfully installed undetected-chromedriver-3.5.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'undetected-chromedriver' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'undetected-chromedriver'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "! pip install undetected-chromedriver beautifulsoup4 requests gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d7006",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Versi 1 ‚Äî Full Selenium WebDriver Scraper\n",
    "\n",
    "Versi pertama dari sistem scraper ini menggunakan **Selenium WebDriver sepenuhnya** untuk melakukan otomatisasi pengambilan data sekolah dari situs  \n",
    "[`referensi.data.kemendikdasmen.go.id`](https://referensi.data.kemendikdasmen.go.id).  \n",
    "Seluruh proses ‚Äî mulai dari membuka halaman utama, navigasi antar tab, hingga redirect ke halaman profil sekolah ‚Äî dilakukan secara **langsung di browser Chrome** melalui kontrol Selenium.\n",
    "\n",
    "Pendekatan ini **tidak menggunakan `requests` maupun `BeautifulSoup`**, melainkan sepenuhnya mengandalkan simulasi interaksi pengguna (click, scroll, open tab, dsb).  \n",
    "Metode ini dirancang agar seluruh elemen web yang dimuat secara dinamis (JavaScript-rendered) dapat terbaca sepenuhnya sebelum data diekstraksi.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Metode & Arsitektur\n",
    "\n",
    "- **Selenium WebDriver (Chrome)** digunakan untuk membuka halaman, menavigasi antar tab, dan mengeksekusi interaksi pengguna secara otomatis.\n",
    "- Semua proses ‚Äî mulai dari pengambilan daftar sekolah hingga data detail ‚Äî dilakukan **sinkron dan sekuensial** tanpa multi-threading.\n",
    "- **Navigasi antar domain** (dari `referensi.data.kemendikdasmen.go.id` ke `sekolah.data.kemdikbud.go.id`) dilakukan dengan membuka **tab baru secara langsung di browser**.\n",
    "- **Ekstraksi data** dilakukan menggunakan kombinasi `CSS Selector` dan `XPath`.\n",
    "- **Gradio UI** digunakan untuk menyediakan antarmuka pengguna dalam memilih kecamatan dan kolom data yang ingin diambil.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Alur Proses\n",
    "\n",
    "1. **Membuka Halaman Referensi Sekolah**  \n",
    "   Berdasarkan *kode kecamatan* dari file JSON, Selenium membuka halaman referensi untuk jenjang SD (`value=5`) dan MI (`value=9`).\n",
    "\n",
    "2. **Mengambil Daftar Sekolah (Tabel Utama)**  \n",
    "   Selenium membaca tabel `table#table1` untuk mengambil data dasar:  \n",
    "   - Nama Sekolah  \n",
    "   - NPSN  \n",
    "   - Status  \n",
    "   - Kelurahan  \n",
    "\n",
    "3. **Redirect ke Profil Sekolah (Tab Identitas)**  \n",
    "   Setiap baris sekolah memiliki tautan menuju halaman profil di domain  \n",
    "   `https://sekolah.data.kemdikbud.go.id`.  \n",
    "   Selenium membuka link ini di tab baru menggunakan perintah:\n",
    "   ```python\n",
    "   driver.execute_script(\"window.open(arguments[0]);\", link_kemdikbud)\n",
    "   driver.switch_to.window(driver.window_handles[-1])\n",
    "   Dari halaman tersebut, Selenium mengekstrak:\n",
    "   -  Alamat sekolah\n",
    "   -  Kepala sekolah\n",
    "   -  Jumlah siswa laki-laki\n",
    "   -  Jumlah siswa perempuan\n",
    "4. **Navigasi ke Tab Kontak (Tab 4)**\n",
    "\n",
    "   Selenium kemudian berpindah ke tab kontak di halaman sekolah untuk mengambil data tambahan:\n",
    "   - Nomor telepon\n",
    "   - Email\n",
    "   - Website sekolah\n",
    "\n",
    "5. **Kembali ke Halaman Utama**\n",
    "   \n",
    "   Setelah data diambil, Selenium menutup tab profil dan kembali ke tab utama untuk melanjutkan ke sekolah berikutnya.\n",
    "6. **Penyimpanan Data ke CSV**\n",
    "   \n",
    "   Semua hasil ekstraksi disusun ke dalam list Python dan disimpan sebagai file .csv\n",
    "di folder output/, sesuai dengan nama kecamatan yang dipilih pengguna.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Ciri Teknis & Karakteristik\n",
    "| Aspek                   | Keterangan                                                                |\n",
    "| ----------------------- | ------------------------------------------------------------------------- |\n",
    "| **Metode Scraping**     | Full Selenium Automation (tanpa `requests` / `BeautifulSoup`)             |\n",
    "| **Parallel Processing** | Tidak (sinkron, satu per satu)                                            |\n",
    "| **Redirect Handling**   | `window.open()` + `switch_to.window()`                                    |\n",
    "| **Teknik Ekstraksi**    | Kombinasi CSS Selector & XPath                                            |\n",
    "| **Driver**              | Chrome WebDriver (headless mode)                                          |\n",
    "| **Output**              | File CSV berisi daftar lengkap sekolah SD/MI per kecamatan                |\n",
    "| **Keunggulan**          | Akurat, stabil, dan mampu membaca halaman dinamis berbasis JavaScript     |\n",
    "| **Kelemahan**           | Lambat karena browser memuat seluruh halaman secara penuh setiap redirect |\n",
    "| **Estimasi Waktu**      | ¬±5‚Äì8 Menit per Kecamatan                                                  |\n",
    "\n",
    "### üîπ Ringkasan\n",
    "\n",
    "Versi 1 berfungsi sebagai baseline sistem scraping penuh berbasis Selenium, di mana seluruh proses dikontrol langsung oleh browser.\n",
    "Selenium meniru interaksi manual pengguna untuk memastikan seluruh konten termuat sebelum pengambilan data dilakukan.\n",
    "\n",
    "Pendekatan ini paling akurat, namun juga paling berat secara sumber daya dan waktu, sehingga menjadi dasar pengembangan menuju versi 2 yang lebih cepat dan efisien.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83fe402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengambil data SD di Ambarawa...\n",
      "Mengambil data MI di Ambarawa...\n",
      "Mengambil data MI di Ambarawa...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import gradio as gr\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  SETUP SELENIUM CHROME DRIVER\n",
    "# =====================================================\n",
    "def setup_driver(headless=True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_table_rows(driver, url):\n",
    "    \"\"\"Helper untuk ambil semua baris dari tabel referensi\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\"))\n",
    "    )\n",
    "    try:\n",
    "        select = Select(driver.find_element(By.NAME, \"table1_length\"))\n",
    "        select.select_by_value(\"100\")\n",
    "    except:\n",
    "        pass\n",
    "    return driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "\n",
    "# =====================================================\n",
    "#  AMBIL KODE KECAMATAN DARI JSON\n",
    "# =====================================================\n",
    "def get_kode_kecamatan_from_json(nama_kecamatan, json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    try:\n",
    "        # Buka file JSON\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if not data:\n",
    "            print(\"File JSON kosong.\")\n",
    "            return None\n",
    "\n",
    "        nama_wilayah = next(iter(data))\n",
    "        kabupaten_data = data[nama_wilayah].get(\"kecamatan\", {})\n",
    "\n",
    "        # Cari kecamatan\n",
    "        for nama, kode in kabupaten_data.items():\n",
    "            if nama.lower() == nama_kecamatan.lower():\n",
    "                return kode\n",
    "\n",
    "        print(f\"Kecamatan '{nama_kecamatan}' tidak ditemukan di {nama_wilayah}.\")\n",
    "        return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File JSON '{json_path}' tidak ditemukan.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membaca JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# =====================================================\n",
    "#  DETAIL SEKOLAH (ALAMAT, KEPSEK, SISWA)\n",
    "# =====================================================\n",
    "def get_detail(driver):\n",
    "    alamat, kepsek, siswa_laki, siswa_perempuan = \"-\", \"-\", \"-\", \"-\"\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"label[for='tab-1']\"))\n",
    "        )\n",
    "        rows_identitas = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "        for rp in rows_identitas:\n",
    "            tds = rp.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "            link_elem = tds[3].find_elements(By.TAG_NAME, \"a\")\n",
    "            if not link_elem:\n",
    "                continue\n",
    "            link_kemdikbud = link_elem[0].get_attribute(\"href\")\n",
    "\n",
    "            # Buka tab baru\n",
    "            driver.execute_script(\"window.open(arguments[0]);\", link_kemdikbud)\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"h4.page-header\"))\n",
    "                )\n",
    "\n",
    "                # Alamat\n",
    "                try:\n",
    "                    alamat_elem = driver.find_element(By.CSS_SELECTOR, \"font.small\")\n",
    "                    alamat_text = alamat_elem.text.replace(\"(master referensi)\", \"\").strip()\n",
    "                    alamat = alamat_text if alamat_text else \"-\"\n",
    "                except:\n",
    "                    alamat = \"-\"\n",
    "\n",
    "                # Kepala Sekolah\n",
    "                try:\n",
    "                    kepsek_elem = driver.find_element(By.XPATH, \"//li[contains(., 'Kepala Sekolah')]\")\n",
    "                    kepsek = kepsek_elem.text.split(\":\", 1)[-1].strip()\n",
    "                except:\n",
    "                    kepsek = \"-\"\n",
    "\n",
    "                # Jumlah Siswa Laki-laki\n",
    "                try:\n",
    "                    siswa_laki_elem = driver.find_element( By.XPATH, \"//text()[contains(., 'Siswa Laki-laki')]/following::font[1]\")\n",
    "                    siswa_laki = siswa_laki_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_laki = \"-\"\n",
    "\n",
    "                # Jumlah Siswa Perempuan\n",
    "                try:\n",
    "                    siswa_perempuan_elem = driver.find_element(By.XPATH, \"//text()[contains(., 'Siswa Perempuan')]/following::font[1]\")\n",
    "                    siswa_perempuan = siswa_perempuan_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_perempuan = \"-\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Gagal ambil data detail: {e}\")\n",
    "\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal proses tab identitas: {e}\")\n",
    "\n",
    "    return alamat, kepsek, siswa_laki, siswa_perempuan\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  KONTAK SEKOLAH\n",
    "# =====================================================\n",
    "def get_kontak(driver):\n",
    "    telepon, email, website = \"-\", \"-\", \"-\"\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \"label[for='tab-4']\").click()\n",
    "        sleep(0.5)\n",
    "        rows_kontak = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "        for row in rows_kontak:\n",
    "            tds = row.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "            label = tds[1].text.strip().lower()\n",
    "            value = tds[3].text.strip() or \"-\"\n",
    "            if \"telepon\" in label:\n",
    "                telepon = value if len(value) >= 5 else \"-\"\n",
    "            elif \"email\" in label:\n",
    "                email = value\n",
    "            elif \"website\" in label:\n",
    "                val = value.lower()\n",
    "                website = \"-\" if val in [\"http://-\", \"https://-\"] else val\n",
    "    except:\n",
    "        pass\n",
    "    return telepon, email, website\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  AMBIL DATA SEKOLAH (SD & MI)\n",
    "# =====================================================\n",
    "def get_sd_mi_schools(kode_kecamatan, nama_kecamatan, selected_fields, progress=gr.Progress()):\n",
    "    driver = setup_driver(headless=True)\n",
    "    sekolah_list = []\n",
    "\n",
    "    need_detail = any(f in selected_fields for f in [\"Alamat\", \"Kepala Sekolah\", \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"])\n",
    "    need_kontak = any(f in selected_fields for f in [\"Telepon\", \"Email\", \"Website\"])\n",
    "\n",
    "    for jenjang, value in [(\"SD\", \"5\"), (\"MI\", \"9\")]:\n",
    "        url = f\"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3/all/{value}/all\"\n",
    "        driver.get(url)\n",
    "        sleep(0.5)\n",
    "        print(f\"Mengambil data {jenjang} di {nama_kecamatan}...\")\n",
    "\n",
    "        all_rows = []\n",
    "        try:\n",
    "            get_table_rows(driver, url)\n",
    "            while True:\n",
    "                rows = driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "                all_rows.extend(rows)\n",
    "                next_btn = driver.find_element(By.CSS_SELECTOR, \"#table1_next\")\n",
    "                if \"disabled\" in next_btn.get_attribute(\"class\"):\n",
    "                    break\n",
    "                driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                sleep(1.2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        total = len(all_rows)\n",
    "        processed = 0\n",
    "\n",
    "        for r in all_rows:\n",
    "            data = {}\n",
    "            try:\n",
    "                if \"Nama Sekolah\" in selected_fields:\n",
    "                    data[\"Nama Sekolah\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\").text.strip()\n",
    "                if \"NPSN\" in selected_fields:\n",
    "                    data[\"NPSN\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                if \"Status\" in selected_fields:\n",
    "                    data[\"Status\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(6)\").text.strip()\n",
    "                if \"Kelurahan\" in selected_fields:\n",
    "                    data[\"Kelurahan\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(5)\").text.strip()\n",
    "\n",
    "                if need_detail or need_kontak:\n",
    "                    href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                    driver.execute_script(\"window.open(arguments[0]);\", href)\n",
    "                    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                    if need_detail:\n",
    "                        alamat, kepsek, siswa_laki, siswa_perempuan = get_detail(driver)\n",
    "                        if \"Alamat\" in selected_fields: data[\"Alamat\"] = alamat\n",
    "                        if \"Kepala Sekolah\" in selected_fields: data[\"Kepala Sekolah\"] = kepsek\n",
    "                        if \"Jumlah Siswa Laki-laki\" in selected_fields: data[\"Jumlah Siswa Laki-laki\"] = siswa_laki\n",
    "                        if \"Jumlah Siswa Perempuan\" in selected_fields: data[\"Jumlah Siswa Perempuan\"] = siswa_perempuan\n",
    "\n",
    "                    if need_kontak:\n",
    "                        telepon, email, website = get_kontak(driver)\n",
    "                        if \"Telepon\" in selected_fields: data[\"Telepon\"] = telepon\n",
    "                        if \"Email\" in selected_fields: data[\"Email\"] = email\n",
    "                        if \"Website\" in selected_fields: data[\"Website\"] = website\n",
    "\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "                sekolah_list.append(data)\n",
    "            except:\n",
    "                pass\n",
    "            processed += 1\n",
    "            if total > 0:\n",
    "                progress(processed / total)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # ===== SORTING berdasarkan prioritas =====\n",
    "    sort_priority = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "    sort_key = next((f for f in sort_priority if f in selected_fields), None)\n",
    "    if sort_key:\n",
    "        sekolah_list.sort(key=lambda x: x.get(sort_key, \"\").lower())\n",
    "    return sekolah_list\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  SIMPAN CSV\n",
    "# =====================================================\n",
    "def save_school_list_by_kecamatan(nama_kecamatan, selected_fields):\n",
    "    kode_kecamatan = get_kode_kecamatan_from_json(nama_kecamatan)\n",
    "    sekolah_list = get_sd_mi_schools(kode_kecamatan, nama_kecamatan, selected_fields)\n",
    "    if not sekolah_list:\n",
    "        return f\" Tidak ada data untuk '{nama_kecamatan}'.\", None\n",
    "\n",
    "    folder = \"output\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filename = f\"list_sd_mi_{nama_kecamatan.lower().replace(' ', '_')}.csv\"\n",
    "    path = os.path.join(folder, filename)\n",
    "\n",
    "    full_order = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "    ordered_fields = [col for col in full_order if col in selected_fields]\n",
    "\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=ordered_fields)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(sekolah_list)\n",
    "    return f\"{len(sekolah_list)} sekolah disimpan ke '{path}'\", path\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  GRADIO UI\n",
    "# =====================================================\n",
    "def run_scraper(nama_kecamatan, selected_fields):\n",
    "    if nama_kecamatan in [\"\", \"-- Pilih Kecamatan --\"]:\n",
    "        yield \"Silakan pilih kecamatan terlebih dahulu.\", gr.update(visible=False)\n",
    "        return\n",
    "    if not selected_fields:\n",
    "        yield \"Pilih minimal satu kolom sebelum memulai scraping.\", gr.update(visible=False)\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    status, file_path = save_school_list_by_kecamatan(nama_kecamatan, selected_fields)\n",
    "    durasi = time.time() - start_time\n",
    "    menit, detik = divmod(int(durasi), 60)\n",
    "    waktu_str = f\"\\nWaktu: {menit} menit {detik} detik\" if menit else f\"\\nWaktu: {detik} detik\"\n",
    "\n",
    "    if file_path:\n",
    "        yield f\"{status}{waktu_str}\", gr.update(value=file_path, visible=True)\n",
    "    else:\n",
    "        yield f\"{status}{waktu_str}\", gr.update(visible=False)\n",
    "\n",
    "\n",
    "def create_gradio_ui(json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    nama_wilayah = next(iter(data))\n",
    "    kecamatan_list = sorted(data[nama_wilayah].get(\"kecamatan\", {}).keys())\n",
    "\n",
    "    fields = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "\n",
    "    with gr.Blocks(title=\"Scraper SD/MI Kabupaten Semarang\") as demo:\n",
    "        gr.Markdown(\"## Scraper SD/MI Kabupaten Semarang v1.0 Selenium WebDriver Full\")\n",
    "        kecamatan = gr.Dropdown(\n",
    "            label=\"Pilih Kecamatan\",\n",
    "            choices=[\"-- Pilih Kecamatan --\"] + kecamatan_list,\n",
    "            value=\"-- Pilih Kecamatan --\",\n",
    "            interactive=True\n",
    "        )\n",
    "        kolom = gr.CheckboxGroup(label=\"Pilih Kolom CSV\", choices=fields)\n",
    "        tombol = gr.Button(\"Mulai Scrape\")\n",
    "        status = gr.Textbox(label=\"Status\", lines=3)\n",
    "        file = gr.File(label=\"File CSV\", interactive=False, visible=False)\n",
    "        tombol.click(fn=run_scraper, inputs=[kecamatan, kolom], outputs=[status, file])\n",
    "    return demo\n",
    "\n",
    "\n",
    "ui = create_gradio_ui()\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ec4f8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Versi 2 ‚Äî Hybrid (Selenium + Requests) Scraper\n",
    "\n",
    "Versi kedua merupakan **penyempurnaan besar** dari sistem scraping sebelumnya, dengan fokus pada **kecepatan, stabilitas koneksi, dan efisiensi sumber daya**.  \n",
    "Pendekatan ini menggabungkan **Selenium**, **Requests**, dan **ThreadPoolExecutor** secara optimal untuk memaksimalkan performa tanpa mengorbankan akurasi data.\n",
    "\n",
    "Selenium kini digunakan **hanya untuk tahap awal** (navigasi dan pembacaan tabel dinamis), sementara seluruh proses pengambilan detail sekolah dijalankan menggunakan **HTTP session pooling (keep-alive)** dan **multi-threaded requests**.  \n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Metode & Arsitektur\n",
    "\n",
    "- **Undetected ChromeDriver (uc)** digunakan untuk mengakses halaman referensi utama dan memuat tabel sekolah yang bersifat dinamis.\n",
    "- **Requests.Session** digunakan untuk membuat koneksi HTTP cepat dengan sistem **keep-alive pooling** (hingga 50 koneksi simultan).\n",
    "- **BeautifulSoup** bertugas melakukan parsing cepat terhadap HTML hasil request dari setiap sekolah.\n",
    "- **ThreadPoolExecutor (25 workers)** mempercepat proses pengambilan detail sekolah (Tab-1 & Tab-4) secara paralel.\n",
    "- **Gradio UI** dipertahankan untuk memudahkan pemilihan kecamatan, kolom data, dan pemantauan progress scraping.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Alur Proses\n",
    "\n",
    "1. **Inisialisasi Chrome Driver (Undetected)**  \n",
    "   Selenium digunakan hanya untuk memuat tabel sekolah dari halaman referensi berikut:\n",
    "    https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3/all/{jenjang}/all\n",
    "    untuk jenjang SD (5) dan MI (9).\n",
    "2. **Ekstraksi Daftar Sekolah (via Selenium)**  \n",
    "Selenium membaca tabel `#table1` untuk memperoleh data dasar:\n",
    "- Nama Sekolah  \n",
    "- NPSN  \n",
    "- Status  \n",
    "- Kelurahan  \n",
    "Serta menyimpan setiap **tautan detail sekolah** untuk diproses paralel.\n",
    "\n",
    "3. **Parallel Fetch Detail (Tab-1 + Tab-4)**  \n",
    "Dengan `ThreadPoolExecutor(max_workers=25)`, sistem secara paralel:\n",
    "- Memanggil **Tab Identitas (Tab-1)** ‚Üí mengambil *Alamat*, *Kepala Sekolah*, *Jumlah Siswa L/P*  \n",
    "- Memanggil **Tab Kontak (Tab-4)** ‚Üí mengambil *Telepon*, *Email*, *Website*\n",
    "\n",
    "4. **Kompilasi & Penyimpanan Data**  \n",
    "Hasil seluruh threads digabung dan disimpan dalam file `.csv` di folder `output/`, dengan urutan kolom sesuai pilihan pengguna.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Ciri Teknis & Karakteristik\n",
    "\n",
    "| Aspek                     | Keterangan                                                                 |\n",
    "| -------------------------- | -------------------------------------------------------------------------- |\n",
    "| **Metode Scraping**       | Hybrid++: Selenium (UC) + Requests (Session Pool) + BeautifulSoup + ThreadPoolExecutor |\n",
    "| **Parallel Processing**   | Ya ‚Äî hingga 25 thread sekaligus                                            |\n",
    "| **Optimasi Koneksi**      | HTTP Keep-Alive dengan Pool 50 koneksi aktif                               |\n",
    "| **Driver**                | Undetected ChromeDriver (`uc.Chrome`)                                      |\n",
    "| **Teknik Ekstraksi**      | Selenium untuk tabel, BeautifulSoup untuk parsing detail                   |\n",
    "| **Output**                | File CSV berisi daftar lengkap SD/MI per kecamatan                         |\n",
    "| **Keunggulan**            | Kecepatan tinggi, koneksi stabil, mampu menangani domain redirect dinamis  |\n",
    "| **Kelemahan**             | Lebih kompleks; konsumsi bandwidth lebih besar karena multi-thread request |\n",
    "| **Estimasi Waktu**        | ¬±35 detik ‚Äì 1.5 menit per Kecamatan                                          |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Ringkasan\n",
    "\n",
    "Versi 2 menghadirkan sistem scraping **paling efisien dan stabil** dalam proyek ini.  \n",
    "Dengan pemisahan yang jelas antara proses dinamis (Selenium) dan proses statis (Requests), versi ini memberikan peningkatan performa hingga **5‚Äì6√ó lebih cepat dari versi awal**, sekaligus mengurangi potensi error akibat perubahan domain atau keterlambatan jaringan.\n",
    "\n",
    "Sistem ini siap digunakan untuk **deployment di server backend**, **otomatisasi pengumpulan data pendidikan**, dan **pengolahan data berskala besar antar kecamatan**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e04a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD - Ambarawa\n",
      "MI - Ambarawa\n",
      "Fetch 34 sekolah (parallel)...\n",
      "34 sekolah Ambarawa\n"
     ]
    }
   ],
   "source": [
    "import os, csv, json, time, gradio as gr, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  SETUP DRIVER UNTUK LOKAL\n",
    "# =====================================================\n",
    "def setup_driver_local(headless=True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1600,900\")\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    driver = uc.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(25)\n",
    "    return driver\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  KODE KECAMATAN\n",
    "# =====================================================\n",
    "def get_kode_kecamatan_from_json(nama_kecamatan, json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        nama_wilayah = next(iter(data))\n",
    "        return data[nama_wilayah][\"kecamatan\"].get(nama_kecamatan)\n",
    "    except Exception as e:\n",
    "        print(\"JSON error:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  OPTIMIZED REQUEST SESSION (keep-alive pool)\n",
    "# =====================================================\n",
    "def create_fast_session():\n",
    "    s = requests.Session()\n",
    "    adapter = requests.adapters.HTTPAdapter(pool_connections=50, pool_maxsize=50, max_retries=2)\n",
    "    s.mount(\"http://\", adapter)\n",
    "    s.mount(\"https://\", adapter)\n",
    "    s.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/121 Safari/537.36\"\n",
    "    })\n",
    "    return s\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  FETCH TAB-4 (KONTAK)\n",
    "# =====================================================\n",
    "def fetch_contact(url, selected_fields, session):\n",
    "    result = {}\n",
    "    try:\n",
    "        resp = session.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        if any(f in selected_fields for f in [\"Telepon\", \"Email\", \"Website\"]):\n",
    "            for row in soup.select(\"table tr\"):\n",
    "                tds = row.find_all(\"td\")\n",
    "                if len(tds) >= 4:\n",
    "                    label = tds[1].get_text(strip=True).lower()\n",
    "                    val = tds[3].get_text(strip=True)\n",
    "                    if \"telepon\" in label:\n",
    "                        result[\"Telepon\"] = val if len(val) > 4 else \"-\"\n",
    "                    elif \"email\" in label:\n",
    "                        result[\"Email\"] = val\n",
    "                    elif \"website\" in label:\n",
    "                        result[\"Website\"] = \"-\" if val in [\"http://-\", \"https://-\"] else val\n",
    "    except Exception:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  FETCH PROFIL SEKOLAH (Tab-1 redirect)\n",
    "# =====================================================\n",
    "def fetch_school_profile(url_tabs, session):\n",
    "    result = {\n",
    "        \"Alamat\": \"-\", \"Kepala Sekolah\": \"-\",\n",
    "        \"Jumlah Siswa Laki-laki\": \"-\", \"Jumlah Siswa Perempuan\": \"-\"\n",
    "    }\n",
    "    try:\n",
    "        resp_ref = session.get(url_tabs, timeout=10)\n",
    "        soup_ref = BeautifulSoup(resp_ref.text, \"html.parser\")\n",
    "        link_tag = soup_ref.find(\"a\", href=lambda x: x and \"sekolah.data\" in x)\n",
    "        if not link_tag:\n",
    "            return result\n",
    "\n",
    "        sekolah_url = link_tag[\"href\"].strip()\n",
    "        resp = session.get(sekolah_url, timeout=10)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        #  Alamat\n",
    "        alamat = soup.select_one(\"font.small\")\n",
    "        if alamat:\n",
    "            result[\"Alamat\"] = alamat.text.replace(\"(master referensi)\", \"\").strip()\n",
    "\n",
    "        #  Kepala Sekolah\n",
    "        for li in soup.select(\"li.list-group-item\"):\n",
    "            txt = li.get_text(strip=True)\n",
    "            if \"Kepala Sekolah\" in txt:\n",
    "                result[\"Kepala Sekolah\"] = txt.split(\":\", 1)[-1].strip()\n",
    "                break\n",
    "\n",
    "        #  Jumlah Siswa\n",
    "        div_stat = soup.find(\"div\", class_=\"col-xs-12 col-md-3 text-left\")\n",
    "        if div_stat:\n",
    "            tag_m = div_stat.find(string=lambda t: \"Siswa Laki-laki\" in t)\n",
    "            if tag_m:\n",
    "                font_m = tag_m.find_next(\"font\", class_=\"text-info\")\n",
    "                if font_m:\n",
    "                    result[\"Jumlah Siswa Laki-laki\"] = font_m.text.strip()\n",
    "\n",
    "            tag_f = div_stat.find(string=lambda t: \"Siswa Perempuan\" in t)\n",
    "            if tag_f:\n",
    "                font_f = tag_f.find_next(\"font\", class_=\"text-info\")\n",
    "                if font_f:\n",
    "                    result[\"Jumlah Siswa Perempuan\"] = font_f.text.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal ambil profil sekolah: {e}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  MAIN SCRAPER\n",
    "# =====================================================\n",
    "def get_sd_mi_schools_fast_local(kode_kecamatan, nama_kecamatan, selected_fields, progress=gr.Progress()):\n",
    "    driver = setup_driver_local(True)\n",
    "    session = create_fast_session()\n",
    "    sekolah_list, urls = [], []\n",
    "\n",
    "    need_detail = any(f in selected_fields for f in\n",
    "                      [\"Alamat\", \"Kepala Sekolah\", \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\",\n",
    "                       \"Telepon\", \"Email\", \"Website\"])\n",
    "\n",
    "    for jenjang, value in [(\"SD\", \"5\"), (\"MI\", \"9\")]:\n",
    "        url = f\"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3/all/{value}/all\"\n",
    "        print(f\"{jenjang} - {nama_kecamatan}\")\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\")))\n",
    "        try:\n",
    "            Select(driver.find_element(By.NAME, \"table1_length\")).select_by_value(\"100\")\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for r in driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\"):\n",
    "            data = {}\n",
    "            if \"Nama Sekolah\" in selected_fields:\n",
    "                data[\"Nama Sekolah\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\").text.strip()\n",
    "            if \"NPSN\" in selected_fields:\n",
    "                data[\"NPSN\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "            if \"Status\" in selected_fields:\n",
    "                data[\"Status\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(6)\").text.strip()\n",
    "            if \"Kelurahan\" in selected_fields:\n",
    "                data[\"Kelurahan\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(5)\").text.strip()\n",
    "            if need_detail:\n",
    "                link = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                urls.append((link, data))\n",
    "            else:\n",
    "                sekolah_list.append(data)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    if need_detail:\n",
    "        print(f\"Fetch {len(urls)} sekolah (parallel)...\")\n",
    "        with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "            futures = {\n",
    "                executor.submit(\n",
    "                    lambda l, base: {\n",
    "                        **base,\n",
    "                        **fetch_contact(l, selected_fields, session),\n",
    "                        **fetch_school_profile(l, session)\n",
    "                    }, link, base\n",
    "                ): (link, base) for link, base in urls\n",
    "            }\n",
    "            for i, f in enumerate(as_completed(futures)):\n",
    "                sekolah_list.append(f.result())\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    progress((i + 1) / len(futures))\n",
    "\n",
    "    #  Sorting berdasar kolom pertama yang dipilih\n",
    "    if selected_fields:\n",
    "        sort_key = selected_fields[0]\n",
    "        sekolah_list.sort(key=lambda x: str(x.get(sort_key, \"\")).lower())\n",
    "\n",
    "    print(f\"{len(sekolah_list)} sekolah {nama_kecamatan}\")\n",
    "    return sekolah_list\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  SAVE CSV\n",
    "# =====================================================\n",
    "def save_school_list_by_kecamatan(nama_kecamatan, selected_fields):\n",
    "    kode = get_kode_kecamatan_from_json(nama_kecamatan)\n",
    "    data = get_sd_mi_schools_fast_local(kode, nama_kecamatan, selected_fields)\n",
    "    if not data:\n",
    "        return f\" Tidak ada data '{nama_kecamatan}'\", None\n",
    "\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    path = f\"output/list_sd_mi_{nama_kecamatan.lower().replace(' ', '_')}.csv\"\n",
    "    cols = [c for c in [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ] if c in selected_fields]\n",
    "\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        w.writerows(data)\n",
    "    return f\"{len(data)} sekolah disimpan ke '{path}'\", path\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# GRADIO\n",
    "# =====================================================\n",
    "def run_scraper(nama_kecamatan, selected_fields):\n",
    "    if nama_kecamatan in [\"\", \"-- Pilih Kecamatan --\"]:\n",
    "        yield \"Pilih kecamatan.\", gr.update(visible=False)\n",
    "        return\n",
    "    if not selected_fields:\n",
    "        yield \"Pilih minimal 1 kolom.\", gr.update(visible=False)\n",
    "        return\n",
    "\n",
    "    t0 = time.time()\n",
    "    status, path = save_school_list_by_kecamatan(nama_kecamatan, selected_fields)\n",
    "    dur = int(time.time() - t0)\n",
    "    m, s = divmod(dur, 60)\n",
    "    time_str = f\"\\n{m} menit {s} detik\" if m else f\"\\n{s} detik\"\n",
    "\n",
    "    yield f\"{status}{time_str}\", gr.update(value=path, visible=True if path else False)\n",
    "\n",
    "\n",
    "def create_gradio_ui(json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    nama_wilayah = next(iter(data))\n",
    "    kec_list = sorted(data[nama_wilayah][\"kecamatan\"].keys())\n",
    "\n",
    "    fields = [\"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "              \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "              \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"]\n",
    "\n",
    "    with gr.Blocks(title=\"Scraper SD/MI Semarang ‚Äî v2.0\") as demo:\n",
    "        gr.Markdown(\"## Scraper SD/MI Kab. Semarang ‚Äî v2.0 Hybrid (Selenium + Requests + Thread Pool Executor)\")\n",
    "        kec = gr.Dropdown(label=\"Pilih Kecamatan\",\n",
    "                          choices=[\"-- Pilih Kecamatan --\"] + kec_list,\n",
    "                          value=\"-- Pilih Kecamatan --\")\n",
    "        kolom = gr.CheckboxGroup(label=\"Kolom CSV\", choices=fields)\n",
    "        btn = gr.Button(\"Mulai Scrape\")\n",
    "        stat = gr.Textbox(label=\"Status\", lines=3)\n",
    "        file = gr.File(label=\"File CSV\", visible=False)\n",
    "        btn.click(fn=run_scraper, inputs=[kec, kolom], outputs=[stat, file])\n",
    "    return demo\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ui = create_gradio_ui()\n",
    "    ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
