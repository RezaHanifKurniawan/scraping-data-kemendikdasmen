{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f476ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.10.5 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327db4c",
   "metadata": {},
   "source": [
    "## SCRAP DATA SD DI KABUPATEN SEMARANG LEWAT GMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd2feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.30.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Collecting websocket-client<2.0,>=1.8.0 (from selenium)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting attrs>=23.2.0 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
      "Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio<1.0,>=0.30.0->selenium)\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.6 MB 13.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 9.8 MB/s  0:00:01\n",
      "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached cffi-2.0.0-cp310-cp310-win_amd64.whl (182 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, sniffio, pysocks, pycparser, h11, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "\n",
      "   --- ------------------------------------  1/13 [websocket-client]\n",
      "   --------- ------------------------------  3/13 [pysocks]\n",
      "   ------------ ---------------------------  4/13 [pycparser]\n",
      "   ------------------ ---------------------  6/13 [attrs]\n",
      "   ------------------------ ---------------  8/13 [outcome]\n",
      "   --------------------------- ------------  9/13 [cffi]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------ --------- 10/13 [trio]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ------------------------------------ --- 12/13 [selenium]\n",
      "   ---------------------------------------- 13/13 [selenium]\n",
      "\n",
      "Successfully installed attrs-25.4.0 cffi-2.0.0 h11-0.16.0 outcome-1.3.0.post0 pycparser-2.23 pysocks-1.7.1 selenium-4.36.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.31.0 trio-websocket-0.12.2 websocket-client-1.9.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c218da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib2to3.pgen2 import driver\n",
    "# from pydoc import text\n",
    "# import time\n",
    "# import csv\n",
    "# import json\n",
    "# import re\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# # ==========================\n",
    "# # 1Ô∏è‚É£ Setup Selenium\n",
    "# # ==========================\n",
    "# def setup_driver(headless=False):\n",
    "#     options = Options()\n",
    "#     if headless:\n",
    "#         options.add_argument(\"--headless\")\n",
    "#     options.add_argument(\"--disable-gpu\")\n",
    "#     options.add_argument(\"--no-sandbox\")\n",
    "#     options.add_argument(\"--disable-dev-shm-usage\")\n",
    "#     options.add_argument(\"--window-size=1920,1080\")\n",
    "#     driver = webdriver.Chrome(options=options)\n",
    "#     return driver\n",
    "\n",
    "\n",
    "# # ==========================\n",
    "# # 2Ô∏è‚É£ Load Daftar Kecamatan dari JSON\n",
    "# # ==========================\n",
    "# def load_kecamatan_list(json_path):\n",
    "#     try:\n",
    "#         with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             data = json.load(f)\n",
    "#         kecamatan_list = data[\"Kabupaten Semarang\"][\"kecamatan\"]\n",
    "#         if isinstance(kecamatan_list[0], dict):\n",
    "#             return [item[\"nama\"] for item in kecamatan_list]\n",
    "#         return kecamatan_list\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Gagal memuat data kecamatan: {e}\")\n",
    "#         return []\n",
    "\n",
    "\n",
    "# # ==========================\n",
    "# # 3Ô∏è‚É£ Scrape Maps Berdasarkan Query\n",
    "# # ==========================\n",
    "# def scrape_maps_by_query(kecamatan: str, kabupaten: str, json_path):\n",
    "#     kecamatan = kecamatan.strip().upper()\n",
    "#     kabupaten = kabupaten.strip().title()\n",
    "\n",
    "#     daftar_kec = load_kecamatan_list(json_path)\n",
    "#     if daftar_kec and kecamatan not in daftar_kec:\n",
    "#         print(f\"‚ùå Kecamatan '{kecamatan}' tidak ditemukan di Kabupaten {kabupaten}.\")\n",
    "#         print(\"üìã Kecamatan valid:\", \", \".join(daftar_kec[:5]), \"...\")\n",
    "#         return\n",
    "\n",
    "#     kecamatan = kecamatan.strip().title()\n",
    "#     query = f\"SD di {kecamatan} Kabupaten {kabupaten}\"\n",
    "#     print(f\"\\nüîç Mencari: {query}\\n\")\n",
    "\n",
    "#     driver = setup_driver()\n",
    "#     driver.get(\"https://www.google.com/maps\")\n",
    "#     time.sleep(3)\n",
    "\n",
    "#     search_box = driver.find_element(By.ID, \"searchboxinput\")\n",
    "#     search_box.clear()\n",
    "#     search_box.send_keys(query)\n",
    "#     search_box.send_keys(Keys.ENTER)\n",
    "#     time.sleep(5)\n",
    "\n",
    "#     print(\"üîÑ Memuat semua hasil...\")\n",
    "\n",
    "#     # scroll list hasil\n",
    "#     scrollable_div = driver.find_element(By.CSS_SELECTOR, \"div[role='feed']\")\n",
    "#     last_height, same_count = 0, 0\n",
    "#     while True:\n",
    "#         driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_div)\n",
    "#         time.sleep(2)\n",
    "#         new_height = driver.execute_script(\"return arguments[0].scrollTop\", scrollable_div)\n",
    "#         if new_height == last_height:\n",
    "#             same_count += 1\n",
    "#         else:\n",
    "#             same_count = 0\n",
    "#         if same_count >= 3:\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "\n",
    "#     # ambil semua href hasil\n",
    "#     links = []\n",
    "#     place_links = driver.find_elements(By.CSS_SELECTOR, \"a.hfpxzc\")\n",
    "#     for pl in place_links:\n",
    "#         href = pl.get_attribute(\"href\")\n",
    "#         if href and \"maps/place\" in href:\n",
    "#             links.append(href)\n",
    "            \n",
    "#     print(f\"‚úÖ Ditemukan {len(links)} hasil.\")\n",
    "\n",
    "#     hasil = []\n",
    "\n",
    "#     # loop ke setiap link (anti-refresh DOM)\n",
    "#     for i, link in enumerate(links, start=1):\n",
    "#         try:\n",
    "#             driver.get(link)\n",
    "#             WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.DUwDvf\"))\n",
    "#             )\n",
    "#             time.sleep(2)\n",
    "\n",
    "#             # ambil nama sekolah\n",
    "#             try:\n",
    "#                 nama = driver.find_element(By.CSS_SELECTOR, \"h1.DUwDvf\").text\n",
    "#             except:\n",
    "#                 nama = \"-\"\n",
    "                \n",
    "#             # ambil alamat\n",
    "#             try:\n",
    "#                 alamat = driver.find_element(By.CSS_SELECTOR, \"button[data-item-id*='address']\").text\n",
    "#                 text = alamat\n",
    "\n",
    "#                 # üßπ hilangkan semua karakter non-ASCII & simbol ikon Google (ÓÉà, dsb)\n",
    "#                 text = re.sub(r\"[^\\x20-\\x7E]+\", \"\", text)\n",
    "\n",
    "#                 # cek apakah mengandung pola Plus Code\n",
    "#                 if re.match(r\"^[A-Z0-9]{4,}\\+[A-Z0-9]{2,}\", text):\n",
    "#                     # hapus plus code di depan, termasuk simbol, koma, dan spasi\n",
    "#                     cleaned = re.sub(r\"^[^\\w]*[A-Z0-9]{4,}\\+[A-Z0-9]{2,}[^\\w,]*,?\\s*\", \"\", text)\n",
    "#                     alamat = cleaned.strip()\n",
    "#                 else:\n",
    "#                     alamat = text.strip()\n",
    "\n",
    "#             except:\n",
    "#                 alamat = \"-\"\n",
    "\n",
    "                \n",
    "#             # ambil telepon/WA\n",
    "#             try:\n",
    "#                 telp = driver.find_element(By.CSS_SELECTOR, \"button[data-item-id*='phone:tel']\").text\n",
    "#                 text = telp\n",
    "                \n",
    "#                  # üßπ hilangkan semua karakter non-ASCII & simbol ikon Google (ÓÉà, dsb)\n",
    "#                 text = re.sub(r\"[^\\x20-\\x7E]+\", \"\", text)\n",
    "#                 telp = text.strip()\n",
    "#             except:\n",
    "#                 telp = \"-\"\n",
    "                \n",
    "#             # ambil website\n",
    "#             try:\n",
    "#                 situs = driver.find_element(By.CSS_SELECTOR, \"a[data-item-id*='authority']\").get_attribute(\"href\")\n",
    "#             except:\n",
    "#                 situs = \"-\"\n",
    "                \n",
    "#             hasil.append({\n",
    "#                 \"Nama Sekolah\": nama,\n",
    "#                 \"Alamat\": alamat,\n",
    "#                 \"Telepon/WA\": telp,\n",
    "#                 \"Website\": situs,\n",
    "#             })\n",
    "\n",
    "#             # tombol kembali\n",
    "#             back_btn = driver.find_elements(By.CSS_SELECTOR, \"button[aria-label='Kembali ke hasil pencarian']\")\n",
    "#             if back_btn:\n",
    "#                 back_btn[0].click()\n",
    "#                 time.sleep(1.5)\n",
    "\n",
    "#         except Exception:\n",
    "#             continue\n",
    "\n",
    "#     print(\"‚úÖ Semua hasil telah dimuat.\")\n",
    "\n",
    "#     if not hasil:\n",
    "#         print(\"‚ö†Ô∏è Tidak ditemukan hasil untuk query ini.\")\n",
    "#         return\n",
    "\n",
    "#     filename = f\"maps_sd_{kabupaten.lower()}_{kecamatan.lower()}.csv\"\n",
    "#     with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#         writer = csv.DictWriter(f, fieldnames=hasil[0].keys())\n",
    "#         writer.writeheader()\n",
    "#         writer.writerows(hasil)\n",
    "\n",
    "#     print(f\"üíæ '{len(hasil)}' Data disimpan ke '{filename}'\\n\")\n",
    "    \n",
    "#     driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf0ff2",
   "metadata": {},
   "source": [
    "# KEMENDIKBUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d3a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Mengambil daftar kabupaten/kota di Provinsi Jawa Tengah...\n",
      "\n",
      "üìç Daftar Kabupaten/Kota di Jawa Tengah:\n",
      "============================================================\n",
      "030100 - Kab. Cilacap\n",
      "030200 - Kab. Banyumas\n",
      "030300 - Kab. Purbalingga\n",
      "030400 - Kab. Banjarnegara\n",
      "030500 - Kab. Kebumen\n",
      "030600 - Kab. Purworejo\n",
      "030700 - Kab. Wonosobo\n",
      "030800 - Kab. Magelang\n",
      "030900 - Kab. Boyolali\n",
      "031000 - Kab. Klaten\n",
      "031100 - Kab. Sukoharjo\n",
      "031200 - Kab. Wonogiri\n",
      "031300 - Kab. Karanganyar\n",
      "031400 - Kab. Sragen\n",
      "031500 - Kab. Grobogan\n",
      "031600 - Kab. Blora\n",
      "031700 - Kab. Rembang\n",
      "031800 - Kab. Pati\n",
      "031900 - Kab. Kudus\n",
      "032000 - Kab. Jepara\n",
      "032100 - Kab. Demak\n",
      "032200 - Kab. Semarang\n",
      "032300 - Kab. Temanggung\n",
      "032400 - Kab. Kendal\n",
      "032500 - Kab. Batang\n",
      "032600 - Kab. Pekalongan\n",
      "032700 - Kab. Pemalang\n",
      "032800 - Kab. Tegal\n",
      "032900 - Kab. Brebes\n",
      "036000 - Kota Magelang\n",
      "036100 - Kota Surakarta\n",
      "036200 - Kota Salatiga\n",
      "036300 - Kota Semarang\n",
      "036400 - Kota Pekalongan\n",
      "036500 - Kota Tegal\n",
      "============================================================\n",
      "\n",
      "üì¶ Mengambil daftar kecamatan di Kab. Semarang...\n",
      "‚úÖ Berhasil ambil 19 kecamatan dari Kab. Semarang\n",
      "üíæ Data disimpan ke: data\\kecamatan_kab_semarang.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "def setup_driver(headless=True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_table_rows(driver, url):\n",
    "    \"\"\"Helper untuk ambil semua baris dari tabel referensi\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\"))\n",
    "    )\n",
    "    try:\n",
    "        select = Select(driver.find_element(By.NAME, \"table1_length\"))\n",
    "        select.select_by_value(\"100\")\n",
    "    except:\n",
    "        pass\n",
    "    return driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "\n",
    "\n",
    "def get_kecamatan_jateng_by_kode():\n",
    "    \"\"\"\n",
    "    Ambil daftar kabupaten/kota di Jawa Tengah (030000),\n",
    "    input kode kabupaten/kota (misal 032200),\n",
    "    hasil disimpan ke data/kecamatan_<nama_kab>.json\n",
    "    dalam format JSON hierarkis.\n",
    "    \"\"\"\n",
    "    base_url = \"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/\"\n",
    "    driver = setup_driver(headless=True)\n",
    "    kecamatan_list = []\n",
    "\n",
    "    try:\n",
    "        # 1Ô∏è‚É£ Ambil daftar kabupaten/kota di Provinsi Jawa Tengah\n",
    "        print(\"üì¶ Mengambil daftar kabupaten/kota di Provinsi Jawa Tengah...\")\n",
    "        kab_url = base_url + \"030000/1\"\n",
    "        rows_kab = get_table_rows(driver, kab_url)\n",
    "\n",
    "        kabupaten_list = []\n",
    "        for r in rows_kab:\n",
    "            try:\n",
    "                nama = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                kode = href.split(\"/\")[-2]\n",
    "                kabupaten_list.append({\"nama\": nama, \"kode\": kode})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(\"\\nüìç Daftar Kabupaten/Kota di Jawa Tengah:\")\n",
    "        print(\"=\" * 60)\n",
    "        for k in kabupaten_list:\n",
    "            print(f\"{k['kode']} - {k['nama']}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        kode_input = input(\"\\nMasukkan KODE kabupaten/kota yang ingin discrap (contoh: 032200): \").strip()\n",
    "\n",
    "        kab = next((k for k in kabupaten_list if k[\"kode\"] == kode_input), None)\n",
    "        if not kab:\n",
    "            print(\"‚ùå Kode tidak ditemukan dalam daftar.\")\n",
    "            driver.quit()\n",
    "            return []\n",
    "\n",
    "        print(f\"\\nüì¶ Mengambil daftar kecamatan di {kab['nama']}...\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Ambil daftar kecamatan dari kabupaten/kota terpilih\n",
    "        kec_url = base_url + f\"{kab['kode']}/2\"\n",
    "        rows_kec = get_table_rows(driver, kec_url)\n",
    "\n",
    "        for r in rows_kec:\n",
    "            try:\n",
    "                nama = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                kode = href.split(\"/\")[-2]\n",
    "                kecamatan_list.append({\"nama\": nama, \"kode\": kode, \"url\": href})\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(f\"‚úÖ Berhasil ambil {len(kecamatan_list)} kecamatan dari {kab['nama']}\")\n",
    "\n",
    "        # 3Ô∏è‚É£ Simpan hasil ke data/\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        safe_name = kab[\"nama\"].replace(\" \", \"_\").replace(\".\", \"\").lower()\n",
    "        save_path = os.path.join(\"data\", f\"kecamatan_{safe_name}.json\")\n",
    "\n",
    "        # === Format sesuai contoh Prof ===\n",
    "        json_data = {\n",
    "            kab[\"nama\"]: {\n",
    "                \"kode\": kab[\"kode\"],\n",
    "                \"kecamatan\": {k[\"nama\"]: k[\"kode\"] for k in kecamatan_list}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"üíæ Data disimpan ke: {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Terjadi kesalahan: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return kecamatan_list\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üöÄ Jalankan\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    kecamatan_data = get_kecamatan_jateng_by_kode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Mengambil daftar SD & MI di Kecamatan Ambarawa (kode 032210)...\n",
      "üîó Mengambil data SD dari: https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/032210/3/all/5/all\n",
      "‚úÖ 29 sekolah SD di Ambarawa\n",
      "üîó Mengambil data MI dari: https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/032210/3/all/9/all\n",
      "‚úÖ 5 sekolah MI di Ambarawa\n",
      "‚úÖ 34 sekolah disimpan ke 'output\\list_sd_mi_ambarawa.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from pandas import options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üîß Setup Driver\n",
    "# ==========================\n",
    "def setup_driver(headless=False):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver\n",
    "\n",
    "def get_table_rows(driver, url):\n",
    "    \"\"\"Helper untuk ambil semua baris dari tabel referensi\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\"))\n",
    "    )\n",
    "    try:\n",
    "        select = Select(driver.find_element(By.NAME, \"table1_length\"))\n",
    "        select.select_by_value(\"100\")\n",
    "    except:\n",
    "        pass\n",
    "    return driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "\n",
    "# ==========================\n",
    "# üìÇ Ambil Kode Kecamatan dari JSON\n",
    "# ==========================\n",
    "def get_kode_kecamatan_from_json(nama_kecamatan, json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    try:\n",
    "        # Buka file JSON\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if not data:\n",
    "            print(\"‚ùå File JSON kosong.\")\n",
    "            return None\n",
    "\n",
    "        nama_wilayah = next(iter(data))\n",
    "        kabupaten_data = data[nama_wilayah].get(\"kecamatan\", {})\n",
    "\n",
    "        # Cari kecamatan\n",
    "        for nama, kode in kabupaten_data.items():\n",
    "            if nama.lower() == nama_kecamatan.lower():\n",
    "                return kode\n",
    "\n",
    "        print(f\"‚ùå Kecamatan '{nama_kecamatan}' tidak ditemukan di {nama_wilayah}.\")\n",
    "        return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File JSON '{json_path}' tidak ditemukan.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error saat membaca JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üîç Ambil data Siswa Laki-laki, Kepsek, Alamat dari website sekolah kita kemendikbud\n",
    "# ==========================\n",
    "def get_detail(driver):\n",
    "    alamat, kepsek, siswa_laki, siswa_perempuan = \"-\", \"-\", \"-\", \"-\"\n",
    "\n",
    "    try:\n",
    "        # Tunggu tab identitas muncul\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"label[for='tab-1']\"))\n",
    "        )\n",
    "        rows_identitas = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "\n",
    "        for rp in rows_identitas:\n",
    "            tds = rp.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "\n",
    "            link_elem = tds[3].find_elements(By.TAG_NAME, \"a\")\n",
    "            if not link_elem:\n",
    "                continue\n",
    "\n",
    "            link_kemdikbud = link_elem[0].get_attribute(\"href\")\n",
    "\n",
    "            #  Buka halaman sekolah.data.kemdikbud.go.id\n",
    "            driver.execute_script(\"window.open(arguments[0]);\", link_kemdikbud)\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "            try:\n",
    "                # Tunggu halaman profil terbuka\n",
    "                WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"h4.page-header\"))\n",
    "                )\n",
    "\n",
    "                #  Ambil alamat\n",
    "                try:\n",
    "                    alamat_elem = driver.find_element(By.CSS_SELECTOR, \"font.small\")\n",
    "                    # Bersihkan teks tambahan seperti \"(master referensi)\"\n",
    "                    alamat_elem = alamat_elem.replace(\"(master referensi)\", \"\").text.strip()\n",
    "                    alamat = alamat_elem if alamat_elem else \"-\"\n",
    "                except:\n",
    "                    alamat = \"-\"\n",
    "\n",
    "                #  Ambil Kepala Sekolah\n",
    "                try:\n",
    "                    kepsek_elem = driver.find_element(\n",
    "                        By.XPATH, \"//li[contains(., 'Kepala Sekolah')]\"\n",
    "                    )\n",
    "                    kepsek = kepsek_elem.text.split(\":\", 1)[-1].strip()\n",
    "                except:\n",
    "                    kepsek = \"-\"\n",
    "\n",
    "                #  Ambil jumlah siswa laki-laki\n",
    "                try:\n",
    "                    siswa_laki_elem = driver.find_element(\n",
    "                        By.XPATH,\n",
    "                        \"//text()[contains(., 'Siswa Laki-laki')]/following::font[1]\"\n",
    "                    )\n",
    "                    siswa_laki = siswa_laki_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_laki = \"-\"\n",
    "                    \n",
    "                # Ambil jumlah siswa perempuan \n",
    "                try:\n",
    "                    siswa_perempuan_elem = driver.find_element(\n",
    "                        By.XPATH,\n",
    "                        \"//text()[contains(., 'Siswa Perempuan')]/following::font[1]\"\n",
    "                    )\n",
    "                    siswa_perempuan = siswa_perempuan_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_perempuan = \"-\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Gagal ambil data di sekolah.data.kemdikbud.go.id: {e}\")\n",
    "\n",
    "            # Tutup tab & kembali ke tab utama\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal proses tab identitas: {e}\")\n",
    "\n",
    "    return alamat, kepsek, siswa_laki, siswa_perempuan\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ‚òéÔ∏è Ambil data kontak Referensi Data Kemendikbud\n",
    "# ==========================\n",
    "def get_kontak(driver):\n",
    "    telepon, email, website = \"-\", \"-\", \"-\"\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"label[for='tab-4']\"))\n",
    "        )\n",
    "        driver.find_element(By.CSS_SELECTOR, \"label[for='tab-4']\").click()\n",
    "        rows_kontak = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "\n",
    "        for row in rows_kontak:\n",
    "            tds = row.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "            label = tds[1].text.strip().lower()\n",
    "            value = tds[3].text.strip() or \"-\"\n",
    "            if \"telepon\" in label:\n",
    "                telepon = value if len(value) >= 5 else \"-\"\n",
    "            elif \"email\" in label:\n",
    "                email = value\n",
    "            elif \"website\" in label:\n",
    "                val = value.lower()\n",
    "                website = \"-\" if val in [\"http://-\", \"https://-\"] else val\n",
    "    except:\n",
    "        pass\n",
    "    return telepon, email, website\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üè´ Ambil Daftar Sekolah (SD & MI) dari Referensi Data Kemendikbud\n",
    "# ==========================\n",
    "def get_sd_mi_schools(kode_kecamatan, nama_kecamatan):\n",
    "    driver = setup_driver(headless=False)\n",
    "    sekolah_list = []\n",
    "\n",
    "    for jenjang, value in [(\"SD\", \"5\"), (\"MI\", \"9\")]:\n",
    "        url = f\"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3/all/{value}/all\"\n",
    "        print(f\"üîó Mengambil data {jenjang} dari: {url}\")\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1\"))\n",
    "            )\n",
    "\n",
    "            # Ubah tampilan jadi 100 baris\n",
    "            get_table_rows(driver, url)\n",
    "\n",
    "            rows = driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "            if not rows:\n",
    "                print(f\"‚ö†Ô∏è Tidak ada data {jenjang} di {nama_kecamatan}\")\n",
    "                continue\n",
    "\n",
    "            for r in rows:\n",
    "                try:\n",
    "                    nama = r.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\").text.strip()\n",
    "                    npsn = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                    status = r.find_element(By.CSS_SELECTOR, \"td:nth-child(6)\").text.strip()\n",
    "                    kelurahan = r.find_element(By.CSS_SELECTOR, \"td:nth-child(5)\").text.strip()\n",
    "                    href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "\n",
    "                    # Buka halaman detail\n",
    "                    driver.execute_script(\"window.open(arguments[0]);\", href)\n",
    "                    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                    alamat, kepsek, siswa_laki, siswa_perempuan = get_detail(driver)\n",
    "                    telepon, email, website = get_kontak(driver)\n",
    "\n",
    "                    sekolah_list.append({\n",
    "                        \"Kelurahan\": kelurahan,\n",
    "                        \"Nama Sekolah\": nama,\n",
    "                        \"NPSN\": npsn,\n",
    "                        \"Status\": status,\n",
    "                        \"Kepala Sekolah\": kepsek,\n",
    "                        \"Alamat\": alamat,\n",
    "                        \"Telepon\": telepon,\n",
    "                        \"Email\": email,\n",
    "                        \"Website\": website,\n",
    "                        \"Jumlah Siswa Laki-laki\": siswa_laki,\n",
    "                        \"Jumlah Siswa Perempuan\": siswa_perempuan,\n",
    "                    })\n",
    "\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Gagal proses {nama}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            print(f\"‚úÖ {len(rows)} sekolah {jenjang} di {nama_kecamatan}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Gagal ambil data {jenjang} di {nama_kecamatan}: {e}\")\n",
    "            continue\n",
    "\n",
    "    driver.quit()\n",
    "    # üß© SORTING berdasarkan nama kelurahan\n",
    "    sekolah_list = sorted(sekolah_list, key=lambda x: x[\"Kelurahan\"].lower())\n",
    "    return sekolah_list\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üíæ Simpan ke CSV\n",
    "# ==========================\n",
    "def save_school_list_by_kecamatan(nama_kecamatan):\n",
    "    nama_kecamatan = nama_kecamatan.strip()\n",
    "    kode_kecamatan = get_kode_kecamatan_from_json(nama_kecamatan)\n",
    "    if not kode_kecamatan:\n",
    "        return\n",
    "\n",
    "    print(f\"üìç Mengambil daftar SD & MI di Kecamatan {nama_kecamatan} (kode {kode_kecamatan})...\")\n",
    "    sekolah_list = get_sd_mi_schools(kode_kecamatan, nama_kecamatan)\n",
    "\n",
    "    if not sekolah_list:\n",
    "        print(f\"‚ùå Tidak ditemukan SD atau MI di {nama_kecamatan}.\")\n",
    "        return\n",
    "\n",
    "    folder = \"output\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filename = f\"list_sd_mi_{nama_kecamatan.lower().replace(' ', '_')}.csv\"\n",
    "    fullpath = os.path.join(folder, filename)\n",
    "\n",
    "    with open(fullpath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\n",
    "            \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\", \"Alamat\", \"Telepon\", \"Email\", \"Website\", \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(sekolah_list)\n",
    "\n",
    "    print(f\"‚úÖ {len(sekolah_list)} sekolah disimpan ke '{fullpath}'\")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# üöÄ Jalankan\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    nama_kecamatan = \"Ambarawa\"\n",
    "    save_school_list_by_kecamatan(nama_kecamatan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb0bf4",
   "metadata": {},
   "source": [
    "# CHOSE DATA YANG MAU DISCRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8769021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.49.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.119.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.13.3 (from gradio)\n",
      "  Downloading gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx<1.0,>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe<4.0,>=2.0 (from gradio)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.2.6)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.14.1-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fsspec (from gradio-client==1.13.3->gradio)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting websockets<16.0,>=13.0 (from gradio-client==1.13.3->gradio)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
      "Collecting httpcore==1.* (from httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\miniconda3\\envs\\kp\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
      "Downloading gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
      "   ---------------------------------------- 0.0/63.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.8/63.5 MB 12.6 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 4.5/63.5 MB 11.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 5.5/63.5 MB 10.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 6.8/63.5 MB 8.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 8.4/63.5 MB 8.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 10.0/63.5 MB 8.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 11.8/63.5 MB 8.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 13.6/63.5 MB 8.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 15.5/63.5 MB 8.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 17.3/63.5 MB 8.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 19.1/63.5 MB 8.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 21.0/63.5 MB 8.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 22.5/63.5 MB 8.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 24.4/63.5 MB 8.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 26.2/63.5 MB 8.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 27.8/63.5 MB 8.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 28.8/63.5 MB 8.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 29.9/63.5 MB 8.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 31.2/63.5 MB 8.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 32.5/63.5 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 33.6/63.5 MB 7.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 34.3/63.5 MB 7.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 35.9/63.5 MB 7.5 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 37.2/63.5 MB 7.5 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 38.5/63.5 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 40.1/63.5 MB 7.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 41.7/63.5 MB 7.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 43.0/63.5 MB 7.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 44.6/63.5 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 46.1/63.5 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 47.4/63.5 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 49.0/63.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 50.6/63.5 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 52.4/63.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 54.3/63.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 56.1/63.5 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 57.9/63.5 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 60.0/63.5 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 61.9/63.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  63.2/63.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 63.5/63.5 MB 7.5 MB/s  0:00:08\n",
      "Downloading gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading fastapi-0.119.0-py3-none-any.whl (107 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 564.3/564.3 kB 6.4 MB/s  0:00:00\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.8/7.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.9/7.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.0/7.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 9.8 MB/s  0:00:00\n",
      "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading Brotli-1.1.0-cp310-cp310-win_amd64.whl (357 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading ruff-0.14.1-py3-none-win_amd64.whl (13.4 MB)\n",
      "   ---------------------------------------- 0.0/13.4 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/13.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/13.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.3/13.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.7/13.4 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.0/13.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.4 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.4/13.4 MB 10.3 MB/s  0:00:01\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading ffmpy-0.6.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, websockets, typing-inspection, tqdm, tomlkit, shellingham, semantic-version, ruff, pyyaml, python-multipart, pydantic-core, pillow, orjson, mdurl, markupsafe, httpcore, groovy, fsspec, filelock, ffmpy, click, annotated-types, aiofiles, uvicorn, pydantic, markdown-it-py, jinja2, huggingface-hub, anyio, starlette, rich, httpx, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\n",
      "   -- -------------------------------------  2/38 [websockets]\n",
      "   -- -------------------------------------  2/38 [websockets]\n",
      "   ---- -----------------------------------  4/38 [tqdm]\n",
      "   ------ ---------------------------------  6/38 [shellingham]\n",
      "   -------- -------------------------------  8/38 [ruff]\n",
      "   --------- ------------------------------  9/38 [pyyaml]\n",
      "   ----------- ---------------------------- 11/38 [pydantic-core]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   -------------- ------------------------- 14/38 [mdurl]\n",
      "   ---------------- ----------------------- 16/38 [httpcore]\n",
      "   ------------------ --------------------- 18/38 [fsspec]\n",
      "   ------------------ --------------------- 18/38 [fsspec]\n",
      "   ------------------ --------------------- 18/38 [fsspec]\n",
      "   -------------------- ------------------- 19/38 [filelock]\n",
      "   ---------------------- ----------------- 21/38 [click]\n",
      "   ------------------------ --------------- 23/38 [aiofiles]\n",
      "   ------------------------- -------------- 24/38 [uvicorn]\n",
      "   ------------------------- -------------- 24/38 [uvicorn]\n",
      "   -------------------------- ------------- 25/38 [pydantic]\n",
      "   -------------------------- ------------- 25/38 [pydantic]\n",
      "   -------------------------- ------------- 25/38 [pydantic]\n",
      "   -------------------------- ------------- 25/38 [pydantic]\n",
      "   -------------------------- ------------- 25/38 [pydantic]\n",
      "   --------------------------- ------------ 26/38 [markdown-it-py]\n",
      "   --------------------------- ------------ 26/38 [markdown-it-py]\n",
      "   --------------------------- ------------ 26/38 [markdown-it-py]\n",
      "   ---------------------------- ----------- 27/38 [jinja2]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ----------------------------- ---------- 28/38 [huggingface-hub]\n",
      "   ------------------------------ --------- 29/38 [anyio]\n",
      "   ------------------------------ --------- 29/38 [anyio]\n",
      "   ------------------------------- -------- 30/38 [starlette]\n",
      "   -------------------------------- ------- 31/38 [rich]\n",
      "   -------------------------------- ------- 31/38 [rich]\n",
      "   -------------------------------- ------- 31/38 [rich]\n",
      "   -------------------------------- ------- 31/38 [rich]\n",
      "   --------------------------------- ------ 32/38 [httpx]\n",
      "   ---------------------------------- ----- 33/38 [typer]\n",
      "   ------------------------------------ --- 35/38 [gradio-client]\n",
      "   ------------------------------------- -- 36/38 [fastapi]\n",
      "   ------------------------------------- -- 36/38 [fastapi]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   -------------------------------------- - 37/38 [gradio]\n",
      "   ---------------------------------------- 38/38 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.11.0 brotli-1.1.0 click-8.3.0 fastapi-0.119.0 ffmpy-0.6.3 filelock-3.20.0 fsspec-2025.9.0 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 jinja2-3.1.6 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 orjson-3.11.3 pillow-11.3.0 pydantic-2.11.10 pydantic-core-2.33.2 pydub-0.25.1 python-multipart-0.0.20 pyyaml-6.0.3 rich-14.2.0 ruff-0.14.1 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.48.0 tomlkit-0.13.3 tqdm-4.67.1 typer-0.19.2 typing-inspection-0.4.2 uvicorn-0.38.0 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b83fe402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Mengambil data SD di Ungaran Barat...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import gradio as gr\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# üîß SETUP SELENIUM CHROME DRIVER\n",
    "# =====================================================\n",
    "def setup_driver(headless=True):\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def get_table_rows(driver, url):\n",
    "    \"\"\"Helper untuk ambil semua baris dari tabel referensi\"\"\"\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table#table1 tbody tr\"))\n",
    "    )\n",
    "    try:\n",
    "        select = Select(driver.find_element(By.NAME, \"table1_length\"))\n",
    "        select.select_by_value(\"100\")\n",
    "    except:\n",
    "        pass\n",
    "    return driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "\n",
    "# =====================================================\n",
    "# üìÇ AMBIL KODE KECAMATAN DARI JSON\n",
    "# =====================================================\n",
    "def get_kode_kecamatan_from_json(nama_kecamatan, json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    try:\n",
    "        # Buka file JSON\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if not data:\n",
    "            print(\"‚ùå File JSON kosong.\")\n",
    "            return None\n",
    "\n",
    "        nama_wilayah = next(iter(data))\n",
    "        kabupaten_data = data[nama_wilayah].get(\"kecamatan\", {})\n",
    "\n",
    "        # Cari kecamatan\n",
    "        for nama, kode in kabupaten_data.items():\n",
    "            if nama.lower() == nama_kecamatan.lower():\n",
    "                return kode\n",
    "\n",
    "        print(f\"‚ùå Kecamatan '{nama_kecamatan}' tidak ditemukan di {nama_wilayah}.\")\n",
    "        return None\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File JSON '{json_path}' tidak ditemukan.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error saat membaca JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# =====================================================\n",
    "# üîç DETAIL SEKOLAH (ALAMAT, KEPSEK, SISWA)\n",
    "# =====================================================\n",
    "def get_detail(driver):\n",
    "    alamat, kepsek, siswa_laki, siswa_perempuan = \"-\", \"-\", \"-\", \"-\"\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"label[for='tab-1']\"))\n",
    "        )\n",
    "        rows_identitas = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "        for rp in rows_identitas:\n",
    "            tds = rp.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "            link_elem = tds[3].find_elements(By.TAG_NAME, \"a\")\n",
    "            if not link_elem:\n",
    "                continue\n",
    "            link_kemdikbud = link_elem[0].get_attribute(\"href\")\n",
    "\n",
    "            # Buka tab baru\n",
    "            driver.execute_script(\"window.open(arguments[0]);\", link_kemdikbud)\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 5).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"h4.page-header\"))\n",
    "                )\n",
    "\n",
    "                # Alamat\n",
    "                try:\n",
    "                    alamat_elem = driver.find_element(By.CSS_SELECTOR, \"font.small\")\n",
    "                    alamat_text = alamat_elem.text.replace(\"(master referensi)\", \"\").strip()\n",
    "                    alamat = alamat_text if alamat_text else \"-\"\n",
    "                except:\n",
    "                    alamat = \"-\"\n",
    "\n",
    "                # Kepala Sekolah\n",
    "                try:\n",
    "                    kepsek_elem = driver.find_element(By.XPATH, \"//li[contains(., 'Kepala Sekolah')]\")\n",
    "                    kepsek = kepsek_elem.text.split(\":\", 1)[-1].strip()\n",
    "                except:\n",
    "                    kepsek = \"-\"\n",
    "\n",
    "                # Jumlah Siswa Laki-laki\n",
    "                try:\n",
    "                    siswa_laki_elem = driver.find_element( By.XPATH, \"//text()[contains(., 'Siswa Laki-laki')]/following::font[1]\")\n",
    "                    siswa_laki = siswa_laki_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_laki = \"-\"\n",
    "\n",
    "                # Jumlah Siswa Perempuan\n",
    "                try:\n",
    "                    siswa_perempuan_elem = driver.find_element(By.XPATH, \"//text()[contains(., 'Siswa Perempuan')]/following::font[1]\")\n",
    "                    siswa_perempuan = siswa_perempuan_elem.text.strip()\n",
    "                except:\n",
    "                    siswa_perempuan = \"-\"\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Gagal ambil data detail: {e}\")\n",
    "\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gagal proses tab identitas: {e}\")\n",
    "\n",
    "    return alamat, kepsek, siswa_laki, siswa_perempuan\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# ‚òéÔ∏è KONTAK SEKOLAH\n",
    "# =====================================================\n",
    "def get_kontak(driver):\n",
    "    telepon, email, website = \"-\", \"-\", \"-\"\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \"label[for='tab-4']\").click()\n",
    "        sleep(0.5)\n",
    "        rows_kontak = driver.find_elements(By.CSS_SELECTOR, \"div.tabby-content table tr\")\n",
    "        for row in rows_kontak:\n",
    "            tds = row.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            if len(tds) < 4:\n",
    "                continue\n",
    "            label = tds[1].text.strip().lower()\n",
    "            value = tds[3].text.strip() or \"-\"\n",
    "            if \"telepon\" in label:\n",
    "                telepon = value if len(value) >= 5 else \"-\"\n",
    "            elif \"email\" in label:\n",
    "                email = value\n",
    "            elif \"website\" in label:\n",
    "                val = value.lower()\n",
    "                website = \"-\" if val in [\"http://-\", \"https://-\"] else val\n",
    "    except:\n",
    "        pass\n",
    "    return telepon, email, website\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# üè´ AMBIL DATA SEKOLAH (SD & MI)\n",
    "# =====================================================\n",
    "def get_sd_mi_schools(kode_kecamatan, nama_kecamatan, selected_fields, progress=gr.Progress()):\n",
    "    driver = setup_driver(headless=True)\n",
    "    sekolah_list = []\n",
    "\n",
    "    need_detail = any(f in selected_fields for f in [\"Alamat\", \"Kepala Sekolah\", \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"])\n",
    "    need_kontak = any(f in selected_fields for f in [\"Telepon\", \"Email\", \"Website\"])\n",
    "\n",
    "    for jenjang, value in [(\"SD\", \"5\"), (\"MI\", \"9\")]:\n",
    "        url = f\"https://referensi.data.kemendikdasmen.go.id/pendidikan/dikdas/{kode_kecamatan}/3/all/{value}/all\"\n",
    "        driver.get(url)\n",
    "        sleep(0.5)\n",
    "        print(f\"üîó Mengambil data {jenjang} di {nama_kecamatan}...\")\n",
    "\n",
    "        all_rows = []\n",
    "        try:\n",
    "            get_table_rows(driver, url)\n",
    "            while True:\n",
    "                rows = driver.find_elements(By.CSS_SELECTOR, \"table#table1 tbody tr\")\n",
    "                all_rows.extend(rows)\n",
    "                next_btn = driver.find_element(By.CSS_SELECTOR, \"#table1_next\")\n",
    "                if \"disabled\" in next_btn.get_attribute(\"class\"):\n",
    "                    break\n",
    "                driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                sleep(1.2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        total = len(all_rows)\n",
    "        processed = 0\n",
    "\n",
    "        for r in all_rows:\n",
    "            data = {}\n",
    "            try:\n",
    "                if \"Nama Sekolah\" in selected_fields:\n",
    "                    data[\"Nama Sekolah\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\").text.strip()\n",
    "                if \"NPSN\" in selected_fields:\n",
    "                    data[\"NPSN\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\").text.strip()\n",
    "                if \"Status\" in selected_fields:\n",
    "                    data[\"Status\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(6)\").text.strip()\n",
    "                if \"Kelurahan\" in selected_fields:\n",
    "                    data[\"Kelurahan\"] = r.find_element(By.CSS_SELECTOR, \"td:nth-child(5)\").text.strip()\n",
    "\n",
    "                if need_detail or need_kontak:\n",
    "                    href = r.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "                    driver.execute_script(\"window.open(arguments[0]);\", href)\n",
    "                    driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                    if need_detail:\n",
    "                        alamat, kepsek, siswa_laki, siswa_perempuan = get_detail(driver)\n",
    "                        if \"Alamat\" in selected_fields: data[\"Alamat\"] = alamat\n",
    "                        if \"Kepala Sekolah\" in selected_fields: data[\"Kepala Sekolah\"] = kepsek\n",
    "                        if \"Jumlah Siswa Laki-laki\" in selected_fields: data[\"Jumlah Siswa Laki-laki\"] = siswa_laki\n",
    "                        if \"Jumlah Siswa Perempuan\" in selected_fields: data[\"Jumlah Siswa Perempuan\"] = siswa_perempuan\n",
    "\n",
    "                    if need_kontak:\n",
    "                        telepon, email, website = get_kontak(driver)\n",
    "                        if \"Telepon\" in selected_fields: data[\"Telepon\"] = telepon\n",
    "                        if \"Email\" in selected_fields: data[\"Email\"] = email\n",
    "                        if \"Website\" in selected_fields: data[\"Website\"] = website\n",
    "\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "                sekolah_list.append(data)\n",
    "            except:\n",
    "                pass\n",
    "            processed += 1\n",
    "            if total > 0:\n",
    "                progress(processed / total)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # ===== üî¢ SORTING berdasarkan prioritas =====\n",
    "    sort_priority = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "    sort_key = next((f for f in sort_priority if f in selected_fields), None)\n",
    "    if sort_key:\n",
    "        sekolah_list.sort(key=lambda x: x.get(sort_key, \"\").lower())\n",
    "    return sekolah_list\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# üíæ SIMPAN CSV\n",
    "# =====================================================\n",
    "def save_school_list_by_kecamatan(nama_kecamatan, selected_fields):\n",
    "    kode_kecamatan = get_kode_kecamatan_from_json(nama_kecamatan)\n",
    "    sekolah_list = get_sd_mi_schools(kode_kecamatan, nama_kecamatan, selected_fields)\n",
    "    if not sekolah_list:\n",
    "        return f\"‚ùå Tidak ada data untuk '{nama_kecamatan}'.\", None\n",
    "\n",
    "    folder = \"output\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filename = f\"list_sd_mi_{nama_kecamatan.lower().replace(' ', '_')}.csv\"\n",
    "    path = os.path.join(folder, filename)\n",
    "\n",
    "    full_order = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "    ordered_fields = [col for col in full_order if col in selected_fields]\n",
    "\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=ordered_fields)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(sekolah_list)\n",
    "    return f\"‚úÖ {len(sekolah_list)} sekolah disimpan ke '{path}'\", path\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# üöÄ GRADIO UI\n",
    "# =====================================================\n",
    "def run_scraper(nama_kecamatan, selected_fields):\n",
    "    if nama_kecamatan in [\"\", \"-- Pilih Kecamatan --\"]:\n",
    "        yield \"‚ö†Ô∏è Silakan pilih kecamatan terlebih dahulu.\", gr.update(visible=False)\n",
    "        return\n",
    "    if not selected_fields:\n",
    "        yield \"‚ö†Ô∏è Pilih minimal satu kolom sebelum memulai scraping.\", gr.update(visible=False)\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    status, file_path = save_school_list_by_kecamatan(nama_kecamatan, selected_fields)\n",
    "    durasi = time.time() - start_time\n",
    "    menit, detik = divmod(int(durasi), 60)\n",
    "    waktu_str = f\"\\n‚è±Ô∏è Waktu: {menit} menit {detik} detik\" if menit else f\"\\n‚è±Ô∏è Waktu: {detik} detik\"\n",
    "\n",
    "    if file_path:\n",
    "        yield f\"{status}{waktu_str}\", gr.update(value=file_path, visible=True)\n",
    "    else:\n",
    "        yield f\"{status}{waktu_str}\", gr.update(visible=False)\n",
    "\n",
    "\n",
    "def create_gradio_ui(json_path=\"./list_kecamatan/kecamatan_kab_semarang.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    nama_wilayah = next(iter(data))\n",
    "    kecamatan_list = sorted(data[nama_wilayah].get(\"kecamatan\", {}).keys())\n",
    "\n",
    "    fields = [\n",
    "        \"Kelurahan\", \"Nama Sekolah\", \"NPSN\", \"Status\", \"Kepala Sekolah\",\n",
    "        \"Alamat\", \"Telepon\", \"Email\", \"Website\",\n",
    "        \"Jumlah Siswa Laki-laki\", \"Jumlah Siswa Perempuan\"\n",
    "    ]\n",
    "\n",
    "    with gr.Blocks(title=\"Scraper SD/MI Kabupaten Semarang\") as demo:\n",
    "        gr.Markdown(\"## üè´ Scraper SD/MI Kabupaten Semarang\")\n",
    "        kecamatan = gr.Dropdown(\n",
    "            label=\"Pilih Kecamatan\",\n",
    "            choices=[\"-- Pilih Kecamatan --\"] + kecamatan_list,\n",
    "            value=\"-- Pilih Kecamatan --\",\n",
    "            interactive=True\n",
    "        )\n",
    "        kolom = gr.CheckboxGroup(label=\"Pilih Kolom CSV\", choices=fields)\n",
    "        tombol = gr.Button(\"‚úÖ Mulai Scrape\")\n",
    "        status = gr.Textbox(label=\"Status\", lines=3)\n",
    "        file = gr.File(label=\"üìÅ File CSV\", interactive=False, visible=False)\n",
    "        tombol.click(fn=run_scraper, inputs=[kecamatan, kolom], outputs=[status, file])\n",
    "    return demo\n",
    "\n",
    "\n",
    "ui = create_gradio_ui()\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
